{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models.mobilenetv3 import mobilenet_v3_large\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision.models import MobileNet_V3_Large_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    #img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveModel():\n",
    "    path = \"./bestModel.pth\"\n",
    "    torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testAccuracy():\n",
    "\n",
    "    model.eval()\n",
    "    accuracy = 0.0\n",
    "    total = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (images, labels) in test_loader:\n",
    "            images = images.to(device).float()\n",
    "            labels = labels.to(device)\n",
    "            # run the model on the test set to predict labels\n",
    "            outputs = model(images)\n",
    "            # the label with the highest energy will be our prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            accuracy += (predicted == labels).sum().item()\n",
    "\n",
    "    # compute the accuracy over all test images\n",
    "    accuracy = (100 * accuracy / total)\n",
    "    return(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONSTANTES\n",
    "EPOCH = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"C:\\\\Users\\\\T-GAMER\\\\Downloads\\\\KneeXrayData\\\\KneeXrayData\\\\ClsKLData\\\\kneeKL299\\\\\"\n",
    "#transformacoes a serem feitas na base de dados\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize(255),\n",
    "                                 transforms.PILToTensor()])\n",
    "# load dataset\n",
    "train_dataset = datasets.ImageFolder(filepath + \"train\", transform= transform)\n",
    "validate_dataset = datasets.ImageFolder(filepath + \"val\", transform= transform)\n",
    "test_dataset = datasets.ImageFolder(filepath + \"test\", transform= transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=50, shuffle= True)\n",
    "validate_loader = DataLoader(validate_dataset, batch_size=50, shuffle= True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=50, shuffle= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testa data_loader\n",
    "images, labels = next(iter(train_loader))\n",
    "# helper.imshow(images[0], normalize=False)\n",
    "\n",
    "imshow(images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model will be running on cuda:0 device\n"
     ]
    }
   ],
   "source": [
    "#create model\n",
    "model = None\n",
    "model = mobilenet_v3_large(weights=MobileNet_V3_Large_Weights.DEFAULT, progress=True)\n",
    "model = nn.Sequential(\n",
    "    model,\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(1000, 50),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50, 50),\n",
    "    nn.ReLU(),\n",
    "    #nn.Dropout(p=0.10),\n",
    "    nn.Linear(50, 5),\n",
    "    nn.Softmax(dim=1)\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"The model will be running on\", device, \"device\")\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define optimizer\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     0] loss: 0.002\n",
      "[1,    50] loss: 0.081\n",
      "[1,   100] loss: 0.080\n",
      "[1,   150] loss: 0.080\n",
      "[1,   200] loss: 0.079\n",
      "[1,   250] loss: 0.078\n",
      "[1,   300] loss: 0.076\n",
      "[1,   350] loss: 0.075\n",
      "[1,   400] loss: 0.073\n",
      "[1,   450] loss: 0.075\n",
      "[1,   500] loss: 0.073\n",
      "[1,   550] loss: 0.072\n",
      "For epoch 1 the test accuracy over the whole test set is 41 %\n",
      "[2,     0] loss: 0.002\n",
      "[2,    50] loss: 0.073\n",
      "[2,   100] loss: 0.070\n",
      "[2,   150] loss: 0.071\n",
      "[2,   200] loss: 0.071\n",
      "[2,   250] loss: 0.070\n",
      "[2,   300] loss: 0.070\n",
      "[2,   350] loss: 0.068\n",
      "[2,   400] loss: 0.072\n",
      "[2,   450] loss: 0.069\n",
      "[2,   500] loss: 0.069\n",
      "[2,   550] loss: 0.068\n",
      "For epoch 2 the test accuracy over the whole test set is 50 %\n",
      "[3,     0] loss: 0.001\n",
      "[3,    50] loss: 0.068\n",
      "[3,   100] loss: 0.068\n",
      "[3,   150] loss: 0.068\n",
      "[3,   200] loss: 0.069\n",
      "[3,   250] loss: 0.069\n",
      "[3,   300] loss: 0.068\n",
      "[3,   350] loss: 0.068\n",
      "[3,   400] loss: 0.067\n",
      "[3,   450] loss: 0.068\n",
      "[3,   500] loss: 0.066\n",
      "[3,   550] loss: 0.068\n",
      "For epoch 3 the test accuracy over the whole test set is 54 %\n",
      "[4,     0] loss: 0.001\n",
      "[4,    50] loss: 0.066\n",
      "[4,   100] loss: 0.066\n",
      "[4,   150] loss: 0.065\n",
      "[4,   200] loss: 0.066\n",
      "[4,   250] loss: 0.067\n",
      "[4,   300] loss: 0.067\n",
      "[4,   350] loss: 0.067\n",
      "[4,   400] loss: 0.065\n",
      "[4,   450] loss: 0.066\n",
      "[4,   500] loss: 0.064\n",
      "[4,   550] loss: 0.066\n",
      "For epoch 4 the test accuracy over the whole test set is 57 %\n",
      "[5,     0] loss: 0.001\n",
      "[5,    50] loss: 0.062\n",
      "[5,   100] loss: 0.064\n",
      "[5,   150] loss: 0.063\n",
      "[5,   200] loss: 0.066\n",
      "[5,   250] loss: 0.064\n",
      "[5,   300] loss: 0.064\n",
      "[5,   350] loss: 0.064\n",
      "[5,   400] loss: 0.066\n",
      "[5,   450] loss: 0.064\n",
      "[5,   500] loss: 0.064\n",
      "[5,   550] loss: 0.065\n",
      "For epoch 5 the test accuracy over the whole test set is 58 %\n",
      "[6,     0] loss: 0.001\n",
      "[6,    50] loss: 0.062\n",
      "[6,   100] loss: 0.062\n",
      "[6,   150] loss: 0.066\n",
      "[6,   200] loss: 0.061\n",
      "[6,   250] loss: 0.062\n",
      "[6,   300] loss: 0.064\n",
      "[6,   350] loss: 0.064\n",
      "[6,   400] loss: 0.064\n",
      "[6,   450] loss: 0.064\n",
      "[6,   500] loss: 0.064\n",
      "[6,   550] loss: 0.062\n",
      "For epoch 6 the test accuracy over the whole test set is 60 %\n",
      "[7,     0] loss: 0.001\n",
      "[7,    50] loss: 0.061\n",
      "[7,   100] loss: 0.063\n",
      "[7,   150] loss: 0.061\n",
      "[7,   200] loss: 0.061\n",
      "[7,   250] loss: 0.060\n",
      "[7,   300] loss: 0.060\n",
      "[7,   350] loss: 0.062\n",
      "[7,   400] loss: 0.063\n",
      "[7,   450] loss: 0.063\n",
      "[7,   500] loss: 0.062\n",
      "[7,   550] loss: 0.063\n",
      "For epoch 7 the test accuracy over the whole test set is 60 %\n",
      "[8,     0] loss: 0.001\n",
      "[8,    50] loss: 0.061\n",
      "[8,   100] loss: 0.062\n",
      "[8,   150] loss: 0.062\n",
      "[8,   200] loss: 0.060\n",
      "[8,   250] loss: 0.061\n",
      "[8,   300] loss: 0.061\n",
      "[8,   350] loss: 0.061\n",
      "[8,   400] loss: 0.060\n",
      "[8,   450] loss: 0.063\n",
      "[8,   500] loss: 0.062\n",
      "[8,   550] loss: 0.061\n",
      "For epoch 8 the test accuracy over the whole test set is 59 %\n",
      "[9,     0] loss: 0.001\n",
      "[9,    50] loss: 0.060\n",
      "[9,   100] loss: 0.061\n",
      "[9,   150] loss: 0.061\n",
      "[9,   200] loss: 0.059\n",
      "[9,   250] loss: 0.061\n",
      "[9,   300] loss: 0.061\n",
      "[9,   350] loss: 0.060\n",
      "[9,   400] loss: 0.061\n",
      "[9,   450] loss: 0.062\n",
      "[9,   500] loss: 0.060\n",
      "[9,   550] loss: 0.061\n",
      "For epoch 9 the test accuracy over the whole test set is 59 %\n",
      "[10,     0] loss: 0.001\n",
      "[10,    50] loss: 0.059\n",
      "[10,   100] loss: 0.059\n",
      "[10,   150] loss: 0.061\n",
      "[10,   200] loss: 0.060\n",
      "[10,   250] loss: 0.061\n",
      "[10,   300] loss: 0.060\n",
      "[10,   350] loss: 0.060\n",
      "[10,   400] loss: 0.061\n",
      "[10,   450] loss: 0.060\n",
      "[10,   500] loss: 0.060\n",
      "[10,   550] loss: 0.060\n",
      "For epoch 10 the test accuracy over the whole test set is 59 %\n"
     ]
    }
   ],
   "source": [
    "#train model\n",
    "best_accuracy = 0.0\n",
    "for epoch in range (EPOCH):\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    for i, (images, labels) in enumerate(train_loader, 0):\n",
    "\n",
    "        # get the inputs\n",
    "        images = images.to(device).float()\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # predict classes using images from the training set\n",
    "        outputs = model(images)\n",
    "\n",
    "        # compute the loss based on model output and real labels\n",
    "        loss = criterion(outputs, labels)\n",
    "        # backpropagate the loss\n",
    "        loss.backward()\n",
    "        # adjust parameters based on the calculated gradients\n",
    "        optimizer.step()\n",
    "\n",
    "        # Let's print statistics for every 1,000 images\n",
    "        running_loss += loss.item()     # extract the loss value\n",
    "        if i % 50 == 0:\n",
    "            # print every 1000 (twice per epoch)\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i, running_loss / 1000))\n",
    "            # zero the loss\n",
    "            running_loss = 0.0\n",
    "    # Compute and print the average accuracy fo this epoch when tested over all 10000 test images\n",
    "    accuracy = testAccuracy()\n",
    "    print('For epoch', epoch+1,'the test accuracy over the whole test set is %d %%' % (accuracy))\n",
    "\n",
    "    # we want to save the model if the accuracy is the best\n",
    "    if accuracy > best_accuracy:\n",
    "        saveModel()\n",
    "        best_accuracy = accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
