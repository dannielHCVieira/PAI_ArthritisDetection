{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from imutils import paths\n",
    "import os\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dropout,Flatten,Dense,Input\n",
    "from keras import Sequential\n",
    "from tensorflow.keras.applications.mobilenet_v3 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, array_to_img\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.constants import lb\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import imutils\n",
    "from scipy.spatial import distance as dist\n",
    "from imutils import perspective\n",
    "from imutils import contours"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def midpoint(ptA, ptB):\n",
    "\treturn (ptA[0] + ptB[0]) * 0.5, (ptA[1] + ptB[1]) * 0.5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def matchTemplatePrivate(img):\n",
    "    METHOD = cv.TM_CCOEFF\n",
    "\n",
    "    # lÃª novamente a imagem para evitar dados quebrados\n",
    "    edged_img = cv.adaptiveThreshold(img, 255,\n",
    "                                     cv.ADAPTIVE_THRESH_MEAN_C, cv.THRESH_BINARY_INV, 21, 10)\n",
    "\n",
    "    img2 = img.copy()\n",
    "\n",
    "    # carrega template para joelho esquerdo e direito\n",
    "    template_l = cv.imread(\"../templates/template_L.png\", 0)\n",
    "    template_r = cv.imread(\"../templates/template_R.png\", 0)\n",
    "\n",
    "    # encontra contornos\n",
    "    edged_template_l = cv.adaptiveThreshold(template_r, 255,\n",
    "                                            cv.ADAPTIVE_THRESH_MEAN_C, cv.THRESH_BINARY_INV, 21, 10)\n",
    "\n",
    "    edged_template_r = cv.adaptiveThreshold(template_l, 255,\n",
    "                                            cv.ADAPTIVE_THRESH_MEAN_C, cv.THRESH_BINARY_INV, 21, 10)\n",
    "\n",
    "    w_l, h_l = template_l.shape[::-1]\n",
    "    w_r, h_r = template_l.shape[::-1]\n",
    "\n",
    "    # aplica o math template em ambas as imagens de template\n",
    "    res_l = cv.matchTemplate(edged_img, edged_template_l, METHOD)\n",
    "    res_r = cv.matchTemplate(edged_img, edged_template_r, METHOD)\n",
    "\n",
    "    min_val_l, max_val_l, min_loc_l, max_loc_l = cv.minMaxLoc(res_l)\n",
    "    min_val_r, max_val_r, min_loc_r, max_loc_r = cv.minMaxLoc(res_r)\n",
    "\n",
    "    # define qual imagem deu melhor match\n",
    "    if max_val_r > max_val_l:\n",
    "        top_left = max_loc_r\n",
    "        bottom_right = (top_left[0] + w_r, top_left[1] + h_r)\n",
    "    else:\n",
    "        top_left = max_loc_l\n",
    "        bottom_right = (top_left[0] + w_l, top_left[1] + h_l)\n",
    "\n",
    "    return top_left, bottom_right"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def processImage(image):\n",
    "    image = img_to_array(image, dtype='uint8')\n",
    "    print(type(image))\n",
    "\n",
    "    x, y = matchTemplatePrivate(image)\n",
    "    print(x,y)\n",
    "    image = image[x[1]:y[1],x[0]:y[0]]\n",
    "    image = array_to_img(image)\n",
    "    image = image.resize((224,224))\n",
    "    #image.show()\n",
    "\n",
    "    image = img_to_array(image, dtype='uint8')\n",
    "\n",
    "    return image#cv.cvtColor(image,cv.COLOR_GRAY2RGB)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "image_1 =cv.imread(\"C:\\\\Users\\\\T-GAMER\\\\Downloads\\\\KneeXrayData\\\\KneeXrayData\\\\ClsKLData\\\\kneeKL224\\\\train_preprocessed\\\\0\\\\9898582R.png\", 0)\n",
    "image_2 =cv.imread(\"C:\\\\Users\\\\T-GAMER\\\\Downloads\\\\KneeXrayData\\\\KneeXrayData\\\\ClsKLData\\\\kneeKL224\\\\train_preprocessed\\\\4\\\\9025994L.png\", 0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(type(image_2))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "cv.imshow(\"image1\", image_1)\n",
    "cv.imshow(\"image2\", image_2)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(7, 79) (215, 164)\n",
      "<class 'numpy.ndarray'>\n",
      "(6, 77) (214, 162)\n"
     ]
    }
   ],
   "source": [
    "image_1 = processImage(image_1)\n",
    "image_2 = processImage(image_2)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "gray = cv.GaussianBlur(image_1, (7, 7), 0)\n",
    "# perform edge detection, then perform a dilation + erosion to\n",
    "# close gaps in between object edges\n",
    "edged = cv.Canny(gray, 50, 100)\n",
    "edged = cv.dilate(edged, None, iterations=1)\n",
    "edged = cv.erode(edged, None, iterations=1)\n",
    "# find contours in the edge map\n",
    "cnts = cv.findContours(edged.copy(), cv.RETR_EXTERNAL,\n",
    "\tcv.CHAIN_APPROX_SIMPLE)\n",
    "cnts = imutils.grab_contours(cnts)\n",
    "(cnts, _) = contours.sort_contours(cnts, method=\"top-to-bottom\")\n",
    "colors = ((0, 0, 255), (240, 0, 159), (0, 165, 255), (255, 255, 0),\n",
    "\t(255, 0, 255))\n",
    "refObj = None"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "import math\n",
    "menorDistancia = math.inf\n",
    "distancias = 0\n",
    "cont = 0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "# loop over the contours individually\n",
    "for c in cnts:\n",
    "\t# if the contour is not sufficiently large, ignore it\n",
    "\tif cv.contourArea(c) < 100:\n",
    "\t\tcontinue\n",
    "\t# compute the rotated bounding box of the contour\n",
    "\tbox = cv.minAreaRect(c)\n",
    "\tbox = cv.cv.BoxPoints(box) if imutils.is_cv2() else cv.boxPoints(box)\n",
    "\tbox = np.array(box, dtype=\"int\")\n",
    "\t# order the points in the contour such that they appear\n",
    "\t# in top-left, top-right, bottom-right, and bottom-left\n",
    "\t# order, then draw the outline of the rotated bounding\n",
    "\t# box\n",
    "\tbox = perspective.order_points(box)\n",
    "\t# compute the center of the bounding box\n",
    "\tcX = np.average(box[:, 0])\n",
    "\tcY = np.average(box[:, 1])\n",
    "    # if this is the first contour we are examining (i.e.,\n",
    "\t# the left-most contour), we presume this is the\n",
    "\t# reference object\n",
    "\tif refObj is None:\n",
    "\t\t# unpack the ordered bounding box, then compute the\n",
    "\t\t# midpoint between the top-left and top-right points,\n",
    "\t\t# followed by the midpoint between the top-right and\n",
    "\t\t# bottom-right\n",
    "\t\t(tl, tr, br, bl) = box\n",
    "\t\t(tlblX, tlblY) = midpoint(tl, bl)\n",
    "\t\t(trbrX, trbrY) = midpoint(tr, br)\n",
    "\t\t# compute the Euclidean distance between the midpoints,\n",
    "\t\t# then construct the reference object\n",
    "\t\tD = dist.euclidean((tlblX, tlblY), (trbrX, trbrY))\n",
    "\t\trefObj = (box, (cX, cY), D / 224)\n",
    "\t\tcontinue\n",
    "    # draw the contours on the image\n",
    "\torig = image_1.copy()\n",
    "\tcv.drawContours(orig, [box.astype(\"int\")], -1, (0, 255, 0), 2)\n",
    "\tcv.drawContours(orig, [refObj[0].astype(\"int\")], -1, (0, 255, 0), 2)\n",
    "\t# stack the reference coordinates and the object coordinates\n",
    "\t# to include the object center\n",
    "\trefCoords = np.vstack([refObj[0], refObj[1]])\n",
    "\tobjCoords = np.vstack([box, (cX, cY)])\n",
    "    # loop over the original points\n",
    "\tfor ((xA, yA), (xB, yB), color) in zip(refCoords, objCoords, colors):\n",
    "\t\t# draw circles corresponding to the current points and\n",
    "\t\t# connect them with a line\n",
    "\t\tcv.circle(orig, (int(xA), int(yA)), 5, color, -1)\n",
    "\t\tcv.circle(orig, (int(xB), int(yB)), 5, color, -1)\n",
    "\t\tcv.line(orig, (int(xA), int(yA)), (int(xB), int(yB)),\n",
    "\t\t\tcolor, 2)\n",
    "\t\t# compute the Euclidean distance between the coordinates,\n",
    "\t\t# and then convert the distance in pixels to distance in\n",
    "\t\t# units\n",
    "\t\tD = dist.euclidean((xA, yA), (xB, yB)) / refObj[2]\n",
    "\n",
    "\t\tdistancias += D\n",
    "\t\tcont+=1\n",
    "\t\tif D< menorDistancia:\n",
    "\t\t\tmenorDistancia = D\n",
    "\n",
    "\t\t(mX, mY) = midpoint((xA, yA), (xB, yB))\n",
    "\t\tcv.putText(orig, \"{:.1f}in\".format(D), (int(mX), int(mY - 10)),\n",
    "\t\t\tcv.FONT_HERSHEY_SIMPLEX, 0.55, color, 2)\n",
    "\t    # show the output image\n",
    "\t\t#cv.imshow(\"Image\", orig)\n",
    "\t\t#cv.waitKey(0)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143.4461532652545\n",
      "68.09589772291052\n"
     ]
    }
   ],
   "source": [
    "print(distancias/cont)\n",
    "print(menorDistancia)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
