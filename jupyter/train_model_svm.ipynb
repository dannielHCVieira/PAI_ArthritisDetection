{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bddc857c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from imutils import paths\n",
    "import os\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dropout,Flatten,Dense,Input\n",
    "from keras import Sequential\n",
    "from tensorflow.keras.applications.mobilenet_v3 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, array_to_img\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from scipy.constants import lb\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import math\n",
    "import imutils\n",
    "from scipy.spatial import distance as dist\n",
    "from imutils import perspective\n",
    "from imutils import contours\n",
    "from sklearn.impute import SimpleImputer\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "094fc16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def midpoint(ptA, ptB):\n",
    "\treturn (ptA[0] + ptB[0]) * 0.5, (ptA[1] + ptB[1]) * 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c33edcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matchTemplatePrivate(img):\n",
    "    METHOD = cv.TM_CCOEFF\n",
    "\n",
    "    # lê novamente a imagem para evitar dados quebrados\n",
    "    edged_img = cv.adaptiveThreshold(img, 255,\n",
    "                                     cv.ADAPTIVE_THRESH_MEAN_C, cv.THRESH_BINARY_INV, 21, 10)\n",
    "\n",
    "    img2 = img.copy()\n",
    "\n",
    "    # carrega template para joelho esquerdo e direito\n",
    "    template_l = cv.imread(\"../templates/template_L.png\", 0)\n",
    "    template_r = cv.imread(\"../templates/template_R.png\", 0)\n",
    "\n",
    "    # encontra contornos\n",
    "    edged_template_l = cv.adaptiveThreshold(template_r, 255,\n",
    "                                            cv.ADAPTIVE_THRESH_MEAN_C, cv.THRESH_BINARY_INV, 21, 10)\n",
    "\n",
    "    edged_template_r = cv.adaptiveThreshold(template_l, 255,\n",
    "                                            cv.ADAPTIVE_THRESH_MEAN_C, cv.THRESH_BINARY_INV, 21, 10)\n",
    "\n",
    "    w_l, h_l = template_l.shape[::-1]\n",
    "    w_r, h_r = template_l.shape[::-1]\n",
    "\n",
    "    # aplica o math template em ambas as imagens de template\n",
    "    res_l = cv.matchTemplate(edged_img, edged_template_l, METHOD)\n",
    "    res_r = cv.matchTemplate(edged_img, edged_template_r, METHOD)\n",
    "\n",
    "    min_val_l, max_val_l, min_loc_l, max_loc_l = cv.minMaxLoc(res_l)\n",
    "    min_val_r, max_val_r, min_loc_r, max_loc_r = cv.minMaxLoc(res_r)\n",
    "\n",
    "    # define qual imagem deu melhor match\n",
    "    if max_val_r > max_val_l:\n",
    "        top_left = max_loc_r\n",
    "        bottom_right = (top_left[0] + w_r, top_left[1] + h_r)\n",
    "    else:\n",
    "        top_left = max_loc_l\n",
    "        bottom_right = (top_left[0] + w_l, top_left[1] + h_l)\n",
    "\n",
    "    return top_left, bottom_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b19cce94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processImage(image):\n",
    "    image = img_to_array(image, dtype='uint8')\n",
    "    x, y = matchTemplatePrivate(image)\n",
    "    image = image[x[1]:y[1],x[0]:y[0]]\n",
    "    image = array_to_img(image)\n",
    "    image = image.resize((224,224))\n",
    "    image = img_to_array(image)\n",
    "    #return cv.cvtColor(image,cv.COLOR_GRAY2RGB)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5887a236",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_distance_between_bones(img):\n",
    "    gray = cv.GaussianBlur(img, (7, 7), 0)\n",
    "    # perform edge detection, then perform a dilation + erosion to\n",
    "    # close gaps in between object edges\n",
    "    edged = cv.Canny(gray, 50, 100)\n",
    "    edged = cv.dilate(edged, None, iterations=1)\n",
    "    edged = cv.erode(edged, None, iterations=1)\n",
    "    # find contours in the edge map\n",
    "    cnts = cv.findContours(edged.copy(), cv.RETR_EXTERNAL,\n",
    "        cv.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "    (cnts, _) = contours.sort_contours(cnts, method=\"top-to-bottom\")\n",
    "    colors = ((0, 0, 255), (240, 0, 159), (0, 165, 255), (255, 255, 0),\n",
    "        (255, 0, 255))\n",
    "    refObj = None\n",
    "    \n",
    "    menorDistancia = math.inf\n",
    "    distancias = 0\n",
    "    cont = 0\n",
    "    \n",
    "    for c in cnts:\n",
    "        # if the contour is not sufficiently large, ignore it\n",
    "        #if cv.contourArea(c) < 10:\n",
    "        #   continue\n",
    "        # compute the rotated bounding box of the contour\n",
    "        box = cv.minAreaRect(c)\n",
    "        box = cv.cv.BoxPoints(box) if imutils.is_cv2() else cv.boxPoints(box)\n",
    "        box = np.array(box, dtype=\"int\")\n",
    "        # order the points in the contour such that they appear\n",
    "        # in top-left, top-right, bottom-right, and bottom-left\n",
    "        # order, then draw the outline of the rotated bounding\n",
    "        # box\n",
    "        box = perspective.order_points(box)\n",
    "        # compute the center of the bounding box\n",
    "        cX = np.average(box[:, 0])\n",
    "        cY = np.average(box[:, 1])\n",
    "        # if this is the first contour we are examining (i.e.,\n",
    "        # the left-most contour), we presume this is the\n",
    "        # reference object\n",
    "        if refObj is None:\n",
    "            # unpack the ordered bounding box, then compute the\n",
    "            # midpoint between the top-left and top-right points,\n",
    "            # followed by the midpoint between the top-right and\n",
    "            # bottom-right\n",
    "            (tl, tr, br, bl) = box\n",
    "            (tlblX, tlblY) = midpoint(tl, bl)\n",
    "            (trbrX, trbrY) = midpoint(tr, br)\n",
    "            # compute the Euclidean distance between the midpoints,\n",
    "            # then construct the reference object\n",
    "            D = dist.euclidean((tlblX, tlblY), (trbrX, trbrY))\n",
    "            refObj = (box, (cX, cY), D / 224)\n",
    "            continue\n",
    "        # draw the contours on the image\n",
    "        orig = img.copy()\n",
    "        cv.drawContours(orig, [box.astype(\"int\")], -1, (0, 255, 0), 2)\n",
    "        cv.drawContours(orig, [refObj[0].astype(\"int\")], -1, (0, 255, 0), 2)\n",
    "        # stack the reference coordinates and the object coordinates\n",
    "        # to include the object center\n",
    "        refCoords = np.vstack([refObj[0], refObj[1]])\n",
    "        objCoords = np.vstack([box, (cX, cY)])\n",
    "        # loop over the original points\n",
    "        for ((xA, yA), (xB, yB), color) in zip(refCoords, objCoords, colors):\n",
    "            \n",
    "            # draw circles corresponding to the current points and\n",
    "            # connect them with a line\n",
    "            cv.circle(orig, (int(xA), int(yA)), 5, color, -1)\n",
    "            cv.circle(orig, (int(xB), int(yB)), 5, color, -1)\n",
    "            cv.line(orig, (int(xA), int(yA)), (int(xB), int(yB)),\n",
    "                color, 2)\n",
    "            # compute the Euclidean distance between the coordinates,\n",
    "            # and then convert the distance in pixels to distance in\n",
    "            # units\n",
    "            D = dist.euclidean((xA, yA), (xB, yB)) / refObj[2]\n",
    "\n",
    "            distancias += D\n",
    "            cont+=1\n",
    "            if D< menorDistancia:\n",
    "                menorDistancia = D\n",
    "\n",
    "            (mX, mY) = midpoint((xA, yA), (xB, yB))\n",
    "            cv.putText(orig, \"{:.1f}in\".format(D), (int(mX), int(mY - 10)),\n",
    "                cv.FONT_HERSHEY_SIMPLEX, 0.55, color, 2)\n",
    "            # show the output image\n",
    "            #cv.imshow(\"Image\", orig)\n",
    "            #cv.waitKey(0)\n",
    "    \n",
    "    if cont == 0:\n",
    "        mediaDistancia = 0\n",
    "    else:\n",
    "        mediaDistancia = (distancias/cont)\n",
    "        \n",
    "    if menorDistancia == math.inf:\n",
    "        menorDistancia = 0\n",
    "    return mediaDistancia, menorDistancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fba3f83c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ba81193",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = \"C:\\\\Users\\\\Windows 10\\\\Documents\\\\PUC\\\\2022_2\\\\PAI\\\\KneeXrayData\\\\ClsKLData\\\\kneeKL224\\\\train_preprocessed\"\n",
    "val_dataset = \"C:\\\\Users\\\\Windows 10\\\\Documents\\\\PUC\\\\2022_2\\\\PAI\\\\KneeXrayData\\\\ClsKLData\\\\kneeKL224\\\\val_preprocessed\"\n",
    "test_dataset = \"C:\\\\Users\\\\Windows 10\\\\Documents\\\\PUC\\\\2022_2\\\\PAI\\\\KneeXrayData\\\\ClsKLData\\\\kneeKL224\\\\test_preprocessed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3ae03c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images=list(paths.list_images(train_dataset))\n",
    "val_images=list(paths.list_images(val_dataset))\n",
    "test_images=list(paths.list_images(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "096d9dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=[]\n",
    "train_labels=[]\n",
    "val_data=[]\n",
    "val_labels=[]\n",
    "test_data=[]\n",
    "test_labels=[]\n",
    "\n",
    "for i in train_images:#adicionar nosso preprocessamento\n",
    "    label=i.split(os.path.sep)[-2]\n",
    "    train_labels.append(label)\n",
    "    image = load_img(i,target_size=(224,224), color_mode=\"grayscale\")\n",
    "    image = processImage(image)\n",
    "    train_data.append(image)\n",
    "\n",
    "for i in val_images:#adicionar nosso preprocessamento\n",
    "    label=i.split(os.path.sep)[-2]\n",
    "    val_labels.append(label)\n",
    "    image = load_img(i,target_size=(224,224), color_mode=\"grayscale\")\n",
    "    image = processImage(image)\n",
    "    val_data.append(image)\n",
    "\n",
    "for i in test_images:#adicionar nosso preprocessamento\n",
    "    label=i.split(os.path.sep)[-2]\n",
    "    test_labels.append(label)\n",
    "    image = load_img(i,target_size=(224,224), color_mode=\"grayscale\")\n",
    "    image = processImage(image)\n",
    "    test_data.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf993e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 1)\n",
      "1652\n",
      "1652\n"
     ]
    }
   ],
   "source": [
    "print(test_data[0].shape)\n",
    "print(len(val_data))\n",
    "print(len(val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f146fa6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=np.array(train_data, dtype='uint8')\n",
    "train_labels=np.array(train_labels)\n",
    "\n",
    "val_data=np.array(val_data, dtype='uint8')\n",
    "val_labels=np.array(val_labels)\n",
    "\n",
    "test_data=np.array(test_data, dtype='uint8')\n",
    "test_labels=np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c88beb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec42b1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n"
     ]
    }
   ],
   "source": [
    "print(find_distance_between_bones(train_data[6346]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a51cd413",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_table = []\n",
    "for data in train_data:\n",
    "    media, menor = find_distance_between_bones(data)\n",
    "    train_data_table.append((media,menor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d41fd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_table = []\n",
    "for data in test_data:\n",
    "    media, menor = find_distance_between_bones(data)\n",
    "    test_data_table.append((media,menor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fb952b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11556"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3821aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imshow(\"aaa\",train_data[6346])\n",
    "cv.imshow(\"bbb\",train_data[6347])\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e270109c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '0', '0', ..., '4', '4', '4'], dtype='<U1')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3720d7c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fee78bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_cat = to_categorical(train_labels)\n",
    "\n",
    "val_labels_cat = to_categorical(val_labels)\n",
    "\n",
    "test_labels_cat = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6ab0e173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11556"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6e1c3b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11556"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89968b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "492425a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel='rbf').fit(train_data_table, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab0ef7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_predict = clf.predict(test_data_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad0868f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_accuracy = accuracy_score(test_labels, clf_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "811d2ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (RBF Kernel):  38.59\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy (RBF Kernel): ', \"%.2f\" % (clf_accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e03cda22",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_np = np.array(train_data_table, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6406b9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.array(train_labels, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "970f521f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instanciar o modelo XGBoost\n",
    "model = XGBClassifiers()\n",
    "# chamar o fit para o modelo\n",
    "history = model.fit(train_data_np, train_labels, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d5ef89aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fazer previsões em cima do dataset de teste\n",
    "predictions = model.predict(test_data_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e2d84186",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows 10\\Documents\\PUC\\2022_2\\PAI\\PAI_ArtroseDetection\\pai\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "plot_confusion_matrix only supports classifiers",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7912\\605178801.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_data_table\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data_table\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Blues'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\PUC\\2022_2\\PAI\\PAI_ArtroseDetection\\pai\\lib\\site-packages\\sklearn\\utils\\deprecation.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFutureWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[0mwrapped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_doc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\PUC\\2022_2\\PAI\\PAI_ArtroseDetection\\pai\\lib\\site-packages\\sklearn\\metrics\\_plot\\confusion_matrix.py\u001b[0m in \u001b[0;36mplot_confusion_matrix\u001b[1;34m(estimator, X, y_true, labels, sample_weight, normalize, display_labels, include_values, xticks_rotation, values_format, cmap, ax, colorbar)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 563\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"plot_confusion_matrix only supports classifiers\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: plot_confusion_matrix only supports classifiers"
     ]
    }
   ],
   "source": [
    "plot_confusion_matrix(model, train_data_table, test_data_table, cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e5fb56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
